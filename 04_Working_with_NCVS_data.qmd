---
title: "Working with National Crime Victimization Survey Data"
author:
- affiliation: University of Pennsylvania
  email: gridge@upenn.edu
  name: Greg Ridgeway
- affiliation: University of Pennsylvania
  email: moyruth@upenn.edu
  name: Ruth Moyer
- affiliation: University of Pennsylvania
  email: gohl@upenn.edu
  name: Li Sian Goh
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    theme: 
      dark: darkly
      light: default
    toc: true
    html-math-method: mathjax
  pdf:
    toc: true
    prefer-html: true
number-sections: true
editor_options: 
  chunk_output_type: console
---


<!-- In terminal -->
<!-- quarto render 04_Working_with_NCVS_data.qmd -->

<!-- git commit 04-* -m "commit message" -->
<!-- git status -->
<!-- git push -->



<!-- A function for automating the numbering and wording of the exercise questions -->
```{r echo=FALSE}
.counterExercise <- 0
.exerciseQuestions <- NULL
.exNum <- function(.questionText="") 
{
   .counterExercise <<- .counterExercise+1
   .exerciseQuestions <<- c(.exerciseQuestions, .questionText)
   .questionText <- gsub("@@", "`", .questionText)
   return(paste0(.counterExercise,". ",.questionText))
}
```




# Introduction

Through our work with NIBRS, we have already discussed reported crime. Nonetheless, not all crimes are reported to the police. Each year, under the guidance of the Bureau of Justice Statistics, the U.S. Census Bureau conducts the National Crime Victimization Survey (NCVS), a source of self-reported victimization data. The Census Bureau interviews a sample of people 12 years old or older about the number and characteristics of crime victimizations they experienced during the prior 6 months. 

In 2023 226,480 people in 142,028 households participated. The survey had a 63\% response rate for households and and 82\% response rate for individuals. Households remain in the sample for $3\frac{1}{2}$ years completing interviews every 6 months, in person or by phone, for a total of seven interviews. The survey cost \$62M annually and required roughly 125,000 hours of uncompensated respondent time.

The NCVS contains information about nonfatal personal crimes, such as rape and robbery, as well as property crimes, such as burglary. Additional information about the NCVS can be found at the [BJS website](https://bjs.ojp.gov/data-collection/ncvs). To give a sense of the type of data that the NCVS contains, refer to the [Official 2023 BJS Crime Victimization report](https://bjs.ojp.gov/library/publications/criminal-victimization-2023).

# Acquiring the NCVS data

The University of Michigan consolidates the NCVS data into a format that is easily accessible in R. We will be using data collected in 2022 and 2023 to assemble a dataset that covers victimizations occurring in 2022. Since respondents are asked about crime in the previous six months, respondents completing surveys in May 2023 will still be reporting about crimes in December 2022.

First, we will download the NCVS 2022 data, [ICPSR 38603](https://www.icpsr.umich.edu/web/NACJD/studies/38603). Click on Download, select R, save the resulting file (called something like ICPSR_38603-V1.zip), extract the contents of the zipped file to a convenient folder, and give it a more understandable folder name, like NCVS2022. Repeat the process for downloading the NCVS 2023 data, [ICPSR 38962](https://www.icpsr.umich.edu/web/NACJD/studies/38962). New NCVS data tends to appear in mid-September. Typically we need to wait about nine months to get the results from the previous year.

After unzipping the NCVS files, you will find subfolders called DS0001, DS0002, DS0003, DS0004, and DS0005. 
```{r}
#| comment: ""
list.files("NCVS2022/",recursive = TRUE)
list.files("NCVS2023/",recursive = TRUE)
```
Inside each of these subfolders you see an R data file with the extension .rda. We will spend most of our attention on the contents of the DS0005 folder, which contains the "incident-level extract file." In each folder you will also find codebooks in pdf (and epub) format. The codebook is as important as it is tedious for understanding what is stored in the NCVS data. You should become familiar with the codebooks as soon as you can.

Let's start loading these datasets. We will skip the DS0001 subfolder, which contains basic survey information on the targeted addressed. The DS0002 folder contains data on the households included in the survey.
```{r}
#| comment: ""
load("NCVS2022/DS0002/38603-0002-Data.rda")
load("NCVS2023/DS0002/38962-0002-Data.rda")

# and let's give them nicer names
dataHH22 <- da38603.0002
dataHH23 <- da38962.0002
```
Take a peek at the first couple of rows
```{r}
#| comment: ""
library(dplyr)
library(tidyr)

dataHH22 |>
  head() |>
  select(V2001, YEARQ, IDHH, V2003, V2014, V2016, V2018, V2020,
         V2030, V2031, V2032, V2034, V2036, V2038, V2040A, V2127B, V2129) 
```
The 2022 household dataset has `r ncol(dataHH22)` columns. Instead of printing out all of them, here I just picked out 17 columns here. First off you can see that the column names are generally not helpful. That is where the codebook comes in handy. The codebook tells you what each variable means.

Somewhat hidden is a table linking column names to English explanations of what is in those columns. You can get to it by extracting the data frame's "attributes" with `attr()`.
```{r}
varsHH <- dataHH22 |>
   attr("variable.labels") |>
   data.frame() |>
   tibble::rownames_to_column() |>
   setNames(c("varname","details")) |>
   filter(!grepl("^HHREP", varname)) # exclude rows that start with HHREP
```
Now `varsHH` has two columns, the first with the column names and the second with the details. Let's pull up the 17 columns listed before.
```{r}
varsHH |>
   filter(varname %in% c("V2001","YEARQ","IDHH","V2003","V2014","V2016",
                         "V2018","V2020","V2030","V2031","V2032","V2034","V2036",
                         "V2038","V2040A","V2127B","V2129")) 
```
These are much more intelligible descriptions. "(S)MSA" stands for the Standard Metropolitan Statistical Areas, an outdated term. Today we call them simply MSAs. Minimum population has to be 50,000, but there is movement toward redefining as 100,000.

Note the first household record has `IDHH` equal to 1809000258543680568236125. We can load the respondent "person file" to see who in this household responded.

```{r}
# loading person-level data
load("NCVS2022/DS0003/38603-0003-Data.rda")
load("NCVS2023/DS0003/38962-0003-Data.rda")
dataPers22 <- da38603.0003
dataPers23 <- da38962.0003

# lookup respondents from this household
dataPers22 |>
  filter(IDHH=="1809000258543680568236125") |>
  select(!starts_with("PERREP"))  # drop all the PERREP weight columns
```
These two rows represent two surveys, six months apart of the same divorced, 62-63 year-old, white male. Let's look up another household.
```{r}
dataPers22 |>
  filter(IDHH=="1809000284384631568236124") |>
  select(!starts_with("PERREP"))
```
These rows represent two surveys occurring at the same time, one of the reference person, a married white female, and a second survey of her husband.

Let's grab the variable details as we did with the household data.
```{r}
#| results: "hold"
# Person file also has list of variable details
varsPers <- dataPers22 |>
   attr("variable.labels") |>
   data.frame() |>
   tibble::rownames_to_column() |>
   setNames(c("varname","details")) |>
   filter(!grepl("^(PERREP|PINTTYPE)", varname))
varsPers
```

There is an incident-level file that we will read in here. We are not going to look at it further, since much of the information in this file is also in the incident extract file.
```{r}
#| results: "hold"
load("NCVS2022/DS0004/38603-0004-Data.rda")
load("NCVS2023/DS0004/38962-0004-Data.rda")
dataInc22 <- da38603.0004
dataInc23 <- da38962.0004

dataInc22 |>
   select(IDHH, IDPER, V4014, V4529) |> 
   head()
```

Finally, we will load in the incident extract file and its associated variable details. This extract file merges in household-level and person-level information to the incident-level file, allowing you to connect person-level features with features of the victimizations they report.
```{r}
#| results: "hold"
# incident-level extract file
load("NCVS2022/DS0005/38603-0005-Data.rda")
load("NCVS2023/DS0005/38962-0005-Data.rda")
dataExt22 <- da38603.0005
dataExt23 <- da38962.0005

varsExt <- dataExt22 |>
   attr("variable.labels") |>
   data.frame() |>
   tibble::rownames_to_column() |>
   setNames(c("varname","details")) |>
   filter(!grepl("INCREPWGT|VICREPWGT", varname))
```

Let's take a look at a few of the reported crime victimizations. Here I will just pull the respondent's age, marital status, sex, general location, and crime type.
```{r}
dataExt22 |>
  select(V3014, V3015, V3018, V4022, V4529) |>
  slice(1:3)
```
Not all information from the household and person files are in the extract file, but many of the features that are likely to be of interest are there.

Now that the datasets are loaded and renamed, we can remove objects from our working environment that we no longer need. We can use `rm()` to accomplish this.
```{r}
#| results: 'hold'
rm(da38603.0001,da38603.0002,da38603.0003,da38603.0004,da38603.0005,
   da38962.0001,da38962.0002,da38962.0003,da38962.0004,da38962.0005)
```

# Combining 2022 and 2023 data

Here we are going to create a data frame containing all the reported incidents that *occurred* in 2022.
Take a look at the month and year of the reported crime incidents.
```{r}
with(dataExt22, table(V4014,V4015)) 
with(dataExt22, table(V4014,V4015))
```
Note that the 2022 NCVS reports on crimes that occurred in 2022 and 2021. Similarly, the NCVS 2023 reports on crimes that occurred in 2023 and 2022. Remember that the NCVS surveys as respondents about any victimizations from the prior 12 months. We will going to stack the 2022 and 2023 incident extract data frames and then filter it to exclude 2021 and 2023.

`bind_rows()` stacks data frames on top of each other, useful when combining two datasets that have the same structure. First we will check that they have the same columns in them.
```{r}
identical(names(dataExt22), names(dataExt23))
```
Good so far! Now let's try to stack them.
```{r}
#| error: true
dataExt <- dataExt22 |>
  bind_rows(dataExt23)
```
Hmmm... R is complaining about `V2061`. Note that it specifically complains that one data frame has `V2061` stored as a factor (a categorical variable) and the other one has it stored as a double, a decimal number.
```{r}
table(dataExt22$V2061, exclude=NULL)
table(dataExt23$V2061, exclude=NULL)
```
What is `V2061` anyway?
```{r}
varsExt |> filter(varname=="V2061")
```
This reports on who reported on behalf of an unavailable respondent. NOt really important for us so let's drop this one by using `select(-V2061)` on both data frames.

```{r}
#| error: true
dataExt <- dataExt22 |>
  select(-V2061) |>
  bind_rows(dataExt23 |>
              select(-V2061))
```
Ughh. Now it is complaining about `V4126`.
```{r}
varsExt |> filter(varname=="V4126")
table(dataExt22$V4126, exclude=NULL)
table(dataExt23$V4126, exclude=NULL)
```
In the codebook we can find the full question: "Q.33.3 Which injuries were caused by a weapon OTHER than a gun or knife?". This seems like a potentially interesting question that I probably do not want to discard. The issue is that no 2023 respondent said there was a third weapon that injured them. In 2022 `V4126` was stored as a factor, but in 2023, since they are all missing, R defaulted to numeric (double). We can fix this by just telling R to convert the 2023 data into a factor.
```{r}
#| error: true
dataExt <- dataExt22 |>
  select(-V2061) |>
  bind_rows(dataExt23 |>
              select(-V2061) |>
              mutate(V4126=as.factor(V4126)))
```
Dammit! Now it is complaining about `V4313`. What is the problem with this one? Again we have a problem with 2022 storing as a factor and 2023 storing as a double.
```{r}
varsExt |> filter(varname=="V4313")
table(dataExt22$V4313, exclude=NULL)
table(dataExt23$V4313, exclude=NULL)
```
This column answers "Besides the respondent, which household member(s) owned the (property/money) the offender tried to take?" In 2022, the only responses were missing or #6. In 2023, the responses were missing, 4, or 5. These should be numbers since they are supposed to link respondents in the same household affected by the theft. The approach I'll take is to use `case_match()` telling R to change the 2022 "(006) 6" response to a regular 6.
```{r}
#| error: true
dataExt <- dataExt22 |>
  select(-V2061) |>
  mutate(V4313 = as.character(V4313),
         V4313 = case_match(V4313,
                            "(006) 6" ~ "6",
                            .default = NA),
         V4313 = as.numeric(V4313)) |>

  bind_rows(dataExt23 |>
              select(-V2061) |>
              mutate(V4126=as.factor(V4126)))
```
Will this ever stop?!?!? Another double in one year and factor in another year, this time affecting `V4357A` asking about handguns.
```{r}
varsExt |> filter(varname=="V4357A")

table(dataExt22$V4357A, exclude=NULL)
table(dataExt23$V4357A, exclude=NULL)
```
You might have seen this word "Residue" show up before. For the NCVS, BJS records "Residue" when there is a data entry error resulting in an out-of-range code, an incorrect or unusable answer by the respondent, or the absence of an entry for a question that should have been asked. Sometimes you might also see "Oout of universe/blank". This happens when a value is outside the range of questions to be answered. For example, "Received Medical Care for Injury", only victims who report being injured are asked whether they received medical care. All other victims skip this question.

I will solve this issue by converting the 2022 values to a factor variable. It would be nice to just make it numeric, but the "(005) 5 handguns or more" response makes that awkward.
```{r}
dataExt <- dataExt22 |>
  select(-V2061) |>
  mutate(V4313 = as.character(V4313),
         V4313 = case_match(V4313,
                            "(06) 6" ~ "6",
                            .default = NA),
         V4313 = as.numeric(V4313),
         V4357A = factor(V4357A,
                         levels=c(1,2,3,997,998),
                         labels=c("(001) 1","(002) 2",
                                  "(003) 3",
                                  "(997) Don't know",
                                  "(998) Residue"))) |>
  bind_rows(dataExt23 |>
              select(-V2061) |>
              mutate(V4126=as.factor(V4126)))
```
Success! Now let's check that all is okay now
```{r}
table(dataExt$V4126,  exclude=NULL)
table(dataExt$V4313,  exclude=NULL)
table(dataExt$V4357A, exclude=NULL)
```

Remember that we still have data in here from 2021 and 2023.
```{r}
table(dataExt$V4015)
```
We are just going to focus on 2022.
```{r}
dataExt <- dataExt |> filter(V4015==2022)
```


# BJS modifications and survey weights























```{r comment="", results='hold'}
dataInc <- rbind(dataInc12,dataInc13)
table(dataInc$V4015) # year crime occured
dataInc <- subset(dataInc, V4015==2012)
```

We will also want to exclude crime that happens outside the United States or crimes for which we do not know the location (NA). According to the Codebook, V4022 refers to location.

```{r comment="", results='hold'}
dataInc <- subset(dataInc, (V4022!="(1) Outside U.S.") | is.na(V4022))
```

A lot of crimes happen in a series. The BJS convention is to include up to 10 occurrences in a series crime.
```{r comment="", results='hold'}
i <- with(dataInc, which((V4019=="(2) No (is series)") & (V4016>=11) & (V4016<=996)))
dataInc$V4016[i] <- 10
dataInc$V4016[dataInc$V4016>=997] <- NA
```

Also, BJS analyses of NCVS data generally use weights because NCVS is survey data. We want to weight the survey data so that they are representative of the wider U.S. population! There are three NCVS weight categories: household, personal, and incident. 

For more information about NCVS weights, consult the section on Weighting Information found at this ICPSR resource guide to the NCVS: (https://www.icpsr.umich.edu/icpsrweb/NACJD/NCVS/accuracy.jsp).

To that extent, let's update the weight for series crimes and create a "date year" weight.
```{r comment="", results='hold'}
i <- which(dataInc$V4019=="(2) No (is series)")
dataInc$WGTVICDY <- dataInc$WGTVICCY
dataInc$WGTVICDY[i] <- with(dataInc, WGTVICDY[i] * V4016[i])
```
We can also tabulate total weight by crime type to estimate the count of a crime. As the Codebook instructs, `V4529` is the variable for crime type.  
```{r comment="", results='hold'}
aggregate(WGTVICDY~V4529, data=dataInc, sum)
```
As you can see, there are some irregularities with the coding of crime types.  Sometimes a type is coded as "(01)", but other times it is coded as "(1)". Let's standardize this coding using regular expressions.
```{r comment="", results='hold'}
dataInc$V4529 <- gsub("\\(([1-9])\\)", "(0\\1)", dataInc$V4529)
aggregate(WGTVICDY~V4529, data=dataInc, sum)
```

Now, we can use the NCVS incident data to find out how many car thefts occurred in 2012. 
```{r comment="", results='hold'}
with(subset(dataInc, V4529=="(40) Motor veh theft"), 
     sum(WGTVICDY))
```

Also, note that the [definition of rape changed](http://www.fbi.gov/about-us/cjis/cjis-link/march-2012/ucr-program-changes-definition-of-rape) in 2013. 
```{r comment="", results='hold'}
with(subset(dataInc,V4529=="(01) Completed rape"), 
     sum(WGTVICDY))
```     

# Merging in data from the household and person data
So far, we've created a dataframe and worked with weights for the Incident data.  However, the Household and Person Data have data that we might need. Let's first create a 2012 data year household data frame, much like we did with the incident data. Note that `YEARQ` refers to the year and quarter of the interview. The variable `V2130` is the month allocated from panel/rotation number. The panel/rotation number refer to [the process](https://www.bjs.gov/content/pub/pdf/ncvs_methodology.pdf) through which interviews are conducted.

```{r comment="", results='hold'}
dataHH <- rbind(dataHH12,dataHH13)
dataHH <- subset(dataHH, YEARQ>=2012.1 & YEARQ<=2013.2)
```
Let's make the "month allocated" uniform, and using regular expressions, delete "0s" following parentheses.
```{r comment="", results='hold'}
table(dataHH$V2130)
dataHH$V2130 <- gsub("\\(0", "\\(", dataHH$V2130)
table(dataHH$V2130)
```
When you view the table again, you can see that the original 21 months listed were condensed into 12.

Next, create a 2012 data year person data frame. We need to first fix incompatible factor/numeric in 2012/2013.  The factor levels in 2012 look like "(1) Yes", but in 2013 are just "1."

```{r comment="", results='hold'}
i <- sapply(dataPers12,levels)                        #gives factor levels for each variable 
i <- i[!sapply(i,is.null)]                             #gives factor levels for each factor variable
                                                       #for non-factor variables, i returns a null result
i <- sapply(i, function(x) all(substring(x,1,1)=="(")) #store in i those variables where the first                                                               #character of factor levels is "(""
var.fix <- names(i)[i]                                 #this gives us the name of variables 
                                                       #where factor levels begin with "(". 

for(xj in var.fix) #create a for-loop to fix these variable names. for each value "xj" in var.fix
{
   dataPers12[,xj] <- gsub("\\(([0-9]+)\\).*","\\1",dataPers12[,xj]) #remove the words that follow the                                                                         #numbers in parentheses
   dataPers12[,xj] <- as.numeric(dataPers12[,xj]) #convert the numbers in parentheses to just numeric                                                       #variables, which present as numbers w/o parentheses
}
```

Then, stack the 2012 and 2013 data frames using `rbind()`.
```{r comment="", results='hold'}
dataPers <- rbind(dataPers12, dataPers13)
dataPers <- subset(dataPers, YEARQ>=2012.1 & YEARQ<=2013.2)
```

Now that we've created a person dataframe and an incident dataframe, we can merge them together. We will use `merge()` to pull age, marital status, and sex into the incident data. The `merge()` function has several parameters that communicate to R which features should be used to match and which ones should be merged. Here we tell `merge()` to use use a pair of features from the incident data (`IDPER` and `YEARQ`) and look up a row in `dataPers` with the same values of `IDPER` and `YEARQ`. We've selected only the five columns `IDPER`, `YEARQ`, `V3014`, `V3015`, and `V3018` from `dataPers`. The first two `merge()` uses to identify matching rows and the last three will be attached as new columns to `dataInc`.

```{r comment=""}
a <- merge(dataInc,                     # incident data
           dataPers[,c("IDPER","YEARQ", # IDPER & YEARQ unique IDs of person
                       "V3014",         # age
                       "V3015",         # marital status
                       "V3018")],       # sex
           by=c("IDPER","YEARQ"),       # variables used to merge
           all.x=TRUE)                  # keep all incidents, even if not matched

# a should have the same number of rows as dataInc, but 3 additional new columns
dim(dataInc)
dim(a)
# replace dataInc with a, now containing age, marital, and sex
dataInc <- a

# check merge for first incident
dataInc[1,c("IDPER","YEARQ","V3014","V3015","V3018")]
# check dataPers for this person's age, marital, and sex
subset(dataPers, IDPER=="250105121075958229372843501" & YEARQ==2012.3,
       select = c("IDPER","YEARQ","V3014","V3015","V3018"))
```

We can see that the first row of `dataInc` now has three additional columns, and that they have the correct values merged from the `dataPers` data.

Let's give these new columns better names.
```{r comment="", results='hold'}
names(dataInc)[names(dataInc)=="V3014"] <- "age"
names(dataInc)[names(dataInc)=="V3015"] <- "marital"
names(dataInc)[names(dataInc)=="V3018"] <- "sex"
```
Let's also create a new variable that breaks age into age categories.
```{r comment="", results='hold'}
dataInc$ageGroup <- cut(dataInc$age, breaks=c(0,16,21,35,45,60,110))
```

Note that "8" is a missing value indicator for marital status. Always refer to the Codebook if you are not sure what a variable or a categorical variable value means.
```{r comment="", results='hold'}
dataInc$marital[dataInc$marital==8] <- NA
```
Factor variables in R put meaningful labels on categorical variables. Instead of working with the numbers 1-5 for marital status, let's assign the number values their actual corresponding names.
```{r comment="", results='hold'}
dataInc$marital <- factor(dataInc$marital, levels=1:5,
                        labels=c("married","widowed","divorced",
                                 "separated","never married"))
dataInc$sex <- factor(dataInc$sex, levels=1:2, 
                      labels=c("male","female"))
```
Let's get estimated counts by age group and sex.
```{r comment="", results='hold'}
aggregate(WGTVICDY~ageGroup+sex, data=dataInc, FUN=sum)
```
We can also find out common crime type by sex. As before, `aggregate()` will total up the weights, but as you see in the ageGroup/sex example above, `aggregate()` produces the results in a long form. Sometimes this is useful, but sometimes we want to have our results side-by-side. We will use `reshape()` to convert the "long format" results from `aggregate()` to a "wide format".
```{r comment="", results='hold'}
a <- aggregate(WGTVICDY~V4529+sex, data=dataInc, FUN=sum)
a <- reshape(a, timevar="sex", idvar="V4529", direction="wide")
a[is.na(a)] <- 0
names(a) <- c("crimeType","male","female")
a
```

We can then convert this result to column percentages. To obtain a column percentage, we divide counts for an individual cell by the total number of counts for the column. So, the sum of all the values in the male column should equal 100:
```{r comment=""}
temp <- a
temp$male   <- with(temp, 100*male/  sum(male))
temp$female <- with(temp, 100*female/sum(female))
colSums(temp[,-1]) # check that the columns sum to 100
temp$ratio <- temp$female/temp$male
temp[order(-temp$ratio),]
```

Or we can compute row percentages to determine what percentage of each crime is male and female.
```{r comment="", results='hold'}
temp <- a
row.total <- with(temp, male+female)
temp$male   <- with(temp, 100*male/  row.total)
temp$female <- with(temp, 100*female/row.total)
rowSums(temp[,-1]) # check that the rows sum to 100
temp$ratio <- temp$female/temp$male
temp[order(-temp$ratio),]
```


