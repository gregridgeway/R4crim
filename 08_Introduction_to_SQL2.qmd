---
title: "Introduction to SQL, Part 2"
author:
- affiliation: University of Pennsylvania
  email: gridge@upenn.edu
  name: Greg Ridgeway
- affiliation: University of Pennsylvania
  email: moyruth@upenn.edu
  name: Ruth Moyer
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    theme: 
      dark: darkly
      light: default
    toc: true
    html-math-method: mathjax
  pdf:
    toc: true
    prefer-html: true
    fig-format: png
number-sections: true
editor_options: 
  chunk_output_type: console
bibliography: G:/My Drive/docs/Greg/articles/mybib.bib
---


<!-- A function for automating the numbering and wording of the exercise questions -->
```{r}
#| echo: false
# Use \x60 in place ` backtick in exercise questions
.counterExercise <- 0
.exerciseQuestions <- NULL
.exNum <- function(.questionText="") 
{
   .counterExercise <<- .counterExercise+1
   .exerciseQuestions <<- c(.exerciseQuestions, .questionText)
   return(paste0(.counterExercise,". ",.questionText))
}
.exQ <- function(i)
{
   return( paste0(i,". ",.exerciseQuestions[i]) )
}

# copy chicagocrime database so its state matches after Lesson 6
file.copy("chicagocrimePost06.db", "chicagocrime.db", overwrite = TRUE)
```

# Creating an IUCR lookup table

The crime table in our Chicago crime database is not ideal. It is overly complicated to extract the year from a date. There is also a lot of redundant information in the table.

Let's take a look at a few example rows.

| Block                     |IUCR| PrimaryType     | FBICode  | Longitude | Latitude |
|:--------------------------|:---|:----------------|:---------|:----------|:---------|
| 040XX W 26TH ST           |0560| ASSAULT         | 08A      | -87.67741 | 41.90842 |
| 089XX S SOUTH CHICAGO AVE |0498| BATTERY         | 04B      | -87.63394 | 41.88602 | 
| 052XX S HARPER AVE        |2820| OTHER OFFENSE   | 26       | -87.62615 | 41.87183 |
| 033XX N TROY ST           |2825| OTHER OFFENSE   | 26       | -87.69560 | 41.85655 |
| 015XX W 107TH ST          |1310| CRIMINAL DAMAGE | 14       | -87.59488 | 41.65512 |
| 0000X N LARAMIE AVE       |2018| NARCOTICS       | 18       | -87.76673 | 41.94523 |
| 0000X N KEELER AVE        |0554| ASSAULT         | 08A      | -87.61501 | 41.76935 |
| 026XX N ELSTON AVE        |0560| ASSAULT         | 08A      | -87.57389 | 41.76742 |
| 076XX S ABERDEEN ST       |0486| BATTERY         | 08B      | -87.64308 | 41.76094 |
| 3XX N SHEFFIELD AVE       |1811| NARCOTICS       | 18       | -87.70109 | 41.79261 |

Note that whenever `IUCR` is 0560, then `PrimaryType` is ASSAULT and `FBICode` is 08A. There is no reason to store the IUCR code, the primary crime type, and the FBI code all in the same file. We should keep a separate table that links the IUCR codes, the primary crime types, and the FBI codes. Note that it is essential to store the IUCR code in the crime table. Both IUCR codes 2018 and 1811 both link to NARCOTICS and FBI code 18. If we deleted IUCR from the crime table and kept only the primary crime type, then we would lose some detailed information. Here is Chicago PD's [listing of FBI codes](https://www.chicagopolice.org/statistics-data/data-requests/).

Aside from reducing database size, eliminating redundant information also provides "update consistency." In the table's current form, we could erroneously add a row that had `IUCR` 0560, `PrimaryType` as BATTERY, and `FBICode` 14. 

| Block                     |IUCR| PrimaryType     | FBICode  | Longitude | Latitude |
|:--------------------------|:---|:----------------|:---------|:----------|:---------|
| 040XX W 26TH ST           |0560| ASSAULT         | 08A      | -87.67741 | 41.90842 |
| 040XX W 26TH ST           |0560| BATTERY         |  14      | -87.67741 | 41.90842 |

The database would not complain even though this is an incorrect combination. IUCR code 0560 *must* link with ASSAULT and 08A. An IUCR lookup table avoids this possibility. The lookup table has each IUCR code showing up only once and always linking to the correct `PrimaryType` and `FBICode`.

|IUCR| PrimaryType     | FBICode  |
|:---|:----------------|:---------|
|0486| BATTERY         | 08B      |
|0498| BATTERY         | 04B      | 
|0554| ASSAULT         | 08A      |
|0560| ASSAULT         | 08A      |
|1310| CRIMINAL DAMAGE | 14       |
|1811| NARCOTICS       | 18       |
|2018| NARCOTICS       | 18       |
|2820| OTHER OFFENSE   | 26       |
|2825| OTHER OFFENSE   | 26       |

Then we can remove `PrimaryType` and `FBICode` from the crime table and look up the associated `PrimaryType` and `FBICode` from the IUCR lookup table whenever we need that information.

Let's start by reconnecting to the Chicago crime database.
```{r} 
#| message: false
library(dplyr)
library(sqldf)
con <- dbConnect(SQLite(), "chicagocrime.db")
```

The SQL keyword `DISTINCT` will filter out any duplicated rows in the result set so that every row is a unique combination of values.
```{r} 
a <- dbGetQuery(con, "
  SELECT DISTINCT IUCR, PrimaryType, FBIcode
  FROM crime")
head(a)
```
This creates a lookup table showing how IUCR links to the primary crime types and FBI codes. We should check that  each IUCR code uniquely links to a single primary type and a single FBI code.
```{r} 
a |> count(IUCR) |> filter(n > 1)
```
Unfortunately, it looks like several IUCR codes have multiple values for `PrimaryType` and/or `FBICode`. Let's start by examining codes 2091, 2092, and 2093.

```{r} 
dbGetQuery(con, "
  SELECT COUNT(*) AS crimecount,
         IUCR,
         PrimaryType,
         FBICode,
         SUBSTR(Date, 7, 4) AS year
  FROM crime
  WHERE IUCR IN ('2091', '2092', '2093')
  GROUP BY IUCR, PrimaryType, year, FBICode
  ORDER BY IUCR, PrimaryType, year, FBICode")
```
These are all narcotics cases, but we see that in some years, these charges are marked as FBI code 18 (crimes of production, sale, use of drugs) and sometimes 26 (a miscellaneous category). FBI code 26 appears more commonly, but the FBI code 26 appears to phase out after 2015. 2091 is a narcotics code for "forfeit property," 2092 is for "soliciting narcotics on a public way," and 2093 is for "found suspect narcotics." It appears that the CPD is now using the more specific FBI codes rather than the generic miscellaneous. The most practical decision is to use the most modern coding and use code 18 for these crimes.

A similar story applies to IUCR crimes 1710, 1715, 1725, 1755, and 1780. These are all offenses involving children that prior to 2016 had been given the FBI miscellaneous code 26, but more recently have been coded as 20 (offenses against family). Again, it seems reasonable to use the most modern coding choice and use FBI code 20.
```{r}
dbGetQuery(con, "
  SELECT COUNT(*) AS crimecount,
         IUCR,
         PrimaryType,
         FBICode,
         SUBSTR(Date, 7, 4) AS year
  FROM crime
  WHERE IUCR IN ('1710','1715','1725','1755','1780')
  GROUP BY IUCR, PrimaryType, year, FBICode
  ORDER BY IUCR, PrimaryType, year, FBICode")
```

IUCR codes 1030 and 1035, which involve possession of incendiary devices, are now being coded as arson (09) rather than miscellaneous (26).
```{r} 
dbGetQuery(con, "
  SELECT COUNT(*) AS crimecount,
         IUCR,
         PrimaryType,
         FBICode,
         SUBSTR(Date,7,4) AS year
  FROM crime
  WHERE IUCR IN ('1030','1035')
  GROUP BY IUCR, PrimaryType, year, FBICode
  ORDER BY IUCR, PrimaryType, year, FBICode")
```
This all points to a modernization of FBI codes where Chicago adopted more specific FBI codes rather than placing them in the miscellaneous category.

Lastly, there are some inconsistent spellings of primary crime types. The spelling of the primary type for 5114 has changed to remove the extra spaces. Even though they differ only by a few spaces, SQL will conclude that these are different values.
```{r}
dbGetQuery(con, 
   "SELECT COUNT(*) AS crimecount,
           IUCR,
           PrimaryType,
           FBICode,
           SUBSTR(Date, 7, 4) AS year
    FROM crime
    WHERE IUCR='5114'
    GROUP BY IUCR, PrimaryType, FBICode, year")
```

Criminal sexual assault also has an inconsistent spelling.
```{r}
dbGetQuery(con, "
  SELECT COUNT(*) AS crimcount,
         PrimaryType,
         year
  FROM crime
  WHERE iucr IN ('0261','0263','0264','0265','0266','0271','0281','0291')
  GROUP BY PrimaryType, year
  ORDER BY year")
```

The conclusion of all of this is that if there is any inconsistency in the connection between `IUCR`, `PrimaryType`, and `FBICode`, then we should choose the most recent combination and delete the rest as options. The following SQL query finds for each IUCR the most recent year that it occurred in the dataset. Not all codes appear in the most recent year. Several IUCR codes last occurred before 2015.
```{r}
dbGetQuery(con, "
    SELECT IUCR, MAX(year) AS maxyear
    FROM crime
    GROUP BY IUCR")
```

Now that we have a query that tells us the most recent year for each IUCR code, we should look up what the `PrimaryType` and `FBICode` are for each `IUCR` in its most recent year. We are going to temporarily create a table with the results from the previous query using "Common Table Expressions" (CTE). A CTE is a temporary table that only lasts for the one query in which it is created. You can have multiple CTEs in one query. Also, here we have our first encounter with a `JOIN`. We will cover more about `JOIN` later in these notes. For now, study the query and see how it solves our problem. With a CTE (the part following the keyword `WITH`) we create a temporary table called `recentIUCR` that has two columns, `IUCR` and `maxyear`. Then the main query looks for rows in the `crime` table that match the rows in `recentIUCR`. When it finds a match, it merges in that crime's `PrimaryType` and `FBICode.` Since many crimes with the same value of `IUCR` show up, we use `DISTINCT` to keep just the unique combinations.

```{r}
iucrLookupTable <- dbGetQuery(con, "
  WITH
     recentIUCR AS
        (SELECT IUCR, MAX(year) AS maxyear
         FROM crime
         GROUP BY IUCR)
  SELECT DISTINCT crime.IUCR, 
                  crime.PrimaryType, 
                  crime.FBICode
  FROM crime
  INNER JOIN recentIUCR
      ON crime.iucr = recentIUCR.iucr AND
         crime.year = recentIUCR.maxyear
  ORDER BY crime.IUCR
")

# check for a few IUCRs
iucrLookupTable |> 
   filter(IUCR %in% c(2091,2092,2093,1030,1035,5114))

# make sure that each IUCR code shows up in only one row
#   should be empty
iucrLookupTable |> 
   count(IUCR) |> 
   filter(n > 1)
```

With questions about IUCR to FBI codes resolved, let's create the IUCR, primary type, and FBI code lookup table in our Chicago crime database. We can use `dbWriteTable()` to post our data frame `iucrLookupTable` to the database, creating a new table called `iucr`.
```{r} 
# remove iucr table if it is there already
if(dbExistsTable(con,"iucr")) dbRemoveTable(con, "iucr")

# import the data frame into SQLite
dbWriteTable(con, "iucr", iucrLookupTable,
             row.names=FALSE)

# check
dbListFields(con,"iucr")

# check whether the table looks correct
dbGetQuery(con, "SELECT * FROM iucr LIMIT 5")
```
Everything looks correct!

Note that we ran a SQL query to pull this lookup table into `iucrLookupTable`, then we wrote that table back to the database with `dbWriteTable()`. There really was no need to pull the table into R, only to post it right back into the database. We can use a `CREATE TABLE` clause to create this lookup table directly in our database.
```{r}
# remove iucr table if it is there already
if(dbExistsTable(con,"iucr")) dbRemoveTable(con, "iucr")

# use dbExecute() since we are creating a table, not retrieving data
dbExecute(con, "
  CREATE TABLE iucr AS
  WITH
     recentIUCR AS
        (SELECT IUCR, MAX(year) AS maxyear
         FROM crime
         GROUP BY IUCR)
  SELECT DISTINCT crime.IUCR, crime.PrimaryType, crime.FBICode
  FROM crime
  INNER JOIN recentIUCR
      ON crime.iucr = recentIUCR.iucr AND
         crime.year = recentIUCR.maxyear
  ORDER BY crime.IUCR
")
```

We now see that our database has two tables, the original `crime` table and the new `iucr` lookup table.
```{r}
dbListTables(con)
```

## Exercises

With the new table `iucr` in the database, complete the following exercises.

`r .exNum('Print out all of the rows in iucr')`

`r .exNum('Print out all the IUCR codes for "KIDNAPPING"')`

`r .exNum('How many IUCR codes are there for "ASSAULT"?')`

`r .exNum('Try doing the prior exercise again using \x60COUNT(*)\x60 if you did not use it the first time')`


# SQL dates
SQLite has no special date/time data type. The `Date` column is currently stored in the `crime` table as plain text. The `PRAGMA` statement is a way to modify or query the SQLite database itself. Here we can ask SQLite the data types it is using to store each of the columns. All the entries, including `Date`, are stored as text, integers, or doubles (numbers with decimal points).
```{r}
dbGetQuery(con, "PRAGMA table_info(crime)")
```

The standard date format in computing is yyyy-mm-dd hh:mm:ss, where the hours are on the 24-hour clock (so no AM/PM). The reason for this format is that you can sort the data in this format to get events in order. For some reason, the producers of the Chicago crime dataset did not use this standard format. If you sort events in the current database, then all the January events will come first (regardless of the year in which they occurred) and any events occurring at 1pm will show up before those occurring at 2am. Putting the dates in a standard format also allows us to use some useful SQLite date functions for extracting the year, day of the week, time of day, and other features of the date and time.

The plan is to create a data frame in R with each crime's `ID` and `Date`. Then we will use `lubridate` to clean up the dates and put them in the standard format. Then we will push a new table into the database containing each crime's `ID` and its newly formatted date.

```{r}
#| message: false
library(lubridate)
data <- dbGetQuery(con, "SELECT ID, Date FROM crime")
data |> head()
```
Since the dates are in mm/dd/yyyy hh:mm:ss format, we will use `mdy_hms()` from the `lubridate` package to clean these up. Fortunately, this function can also handle the AM/PM.
```{r}
data <- data |>
   mutate(datefix = mdy_hms(Date),
          datefix = as.character(datefix)) |> # convert to plain text
   # delete the original date from the data frame
   select(-Date)

# check that the reformatting worked
data |> head()
```

With the dates in standard format, let's push the fixed dates table to the database.
```{r}
# remove DateFix table if it already exists
if(dbExistsTable(con,"DateFix")) dbRemoveTable(con, "DateFix")

# save a table with ID and the properly formatted date
dbWriteTable(con, "DateFix", data, row.names=FALSE)
dbListTables(con)
```
Our database now has three tables with the addition of the new `DateFix` table.

Before we used `SUBSTR()` to extract the year from the date. That was not very elegant and required figuring out which characters held the four characters representing the year. Even though SQLite does not have a date/time type, it does have some functions that help us work with dates. We will use SQLite's `STRFTIME()` function. It stands for "string format time". It is a decades-old function that you will find in almost all languages. Even R has its own version of `strftime()`. Early programming language compilers limited functions to at most eight characters, so programmers got rather creative in shrinking complicated function descriptions down to eight characters.

The `STRFTIME()` function has two primary arguments (and some optional [modifiers](https://sqlite.org/lang_datefunc.html#modifiers)). The first is a format parameter in which you tell `STRFTIME()` what you want it to extract from the date. The second argument is the column containing the dates. There are a lot of options for the format parameter. For example, you can extract just the year (%Y), just the month (%m), just the minute (%M), the day of the week (%w) with Sunday represented as 0 and Saturday as 6, or the week of the year (%W). You can also combine to get, for example, the year and month (%Y-%m). You can find a complete listing [here](https://www.sqlite.org/lang_datefunc.html).

Let's write a query to test out `STRFTIME()`. Here we will select some dates from `DateFix` and determine on which day of the week the crime occurred.
```{r}
a <- dbGetQuery(con, "
  SELECT ID,
         datefix,
         STRFTIME('%w',datefix) AS weekday
  FROM DateFix")
a |> head()
```
For the first date, `r date(ymd_hms(a$datefix[1]))`, `STRFTIME()` tells us that this was day `r a$weekday[1]` of the week, which is `r c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday")[1+as.numeric(a$weekday[1])]` (remember that 0 is Sunday).

`STRFTIME()` always returns values that are text. That is, if you ask for the year using `STRFTIME('%Y',datefix)` and you get values like 2017 and 2018, your results will be character strings rather than numeric. You will have to convert them using `as.numeric()` in R or, preferably, using a `CAST()` expression in SQL. `CAST()` is particularly useful if you want to select records that, say, occur after 2010 or after noon.

Let's count cases that occurred between Monday and Friday after noon.
```{r}
dbGetQuery(con, "
  SELECT COUNT(*) as crimecount,
         CAST(STRFTIME('%w',datefix) AS INTEGER) AS weekday
  FROM DateFix
  WHERE (weekday>=1) AND (weekday<=5) AND
        (CAST(STRFTIME('%H',datefix) AS INTEGER) >= 12)
  GROUP BY weekday")
```
In the `SELECT` clause, we told SQLite to store the weekday as an integer. In the `WHERE` clause we extracted the hour (24-hour clock) so that we could make a numerical comparison with the number 12.

# Creating the final table

Now we can put it all together, drop columns we do not want, remove redundant information, and clean up the dates.

Removing columns from tables in SQLite used to not be simple. Only after March 2021 could you run `ALTER TABLE crime DROP COLUMN Date` to remove a single column. We are going to use an old-school approach since we are going to make many changes to our database. We are going to rename the current `crime` table, then copy only the columns we want into a new `crime` table, while at the same time replacing the old format dates with dates in a more preferable format.

First, rename the `crime` table to `crime_old`, which we will delete as soon as we are done.
```{r}
dbExecute(con, "ALTER TABLE crime RENAME TO crime_old")
```
There should be a new table.
```{r}
dbListTables(con)
```

This will create our new `crime` table. It can take a few minutes.
```{r buildFinalCrimeTable}
dbExecute(con, "
   CREATE TABLE crime AS
   SELECT crime_old.ID,
          crime_old.CaseNumber,
          DateFix.datefix AS date,
          crime_old.Block,
          crime_old.IUCR,
          crime_old.Description,
          crime_old.LocationDescription,
          crime_old.Arrest,
          crime_old.Domestic,
          crime_old.Beat,
          crime_old.District,
          crime_old.Ward,
          crime_old.CommunityArea,
          crime_old.Latitude,
          crime_old.Longitude
   FROM crime_old
      INNER JOIN DateFix
        ON crime_old.ID=DateFix.ID")
```
This query requires a bit of discussion. First, note that the `FROM` clause joins two tables, `crime_old` and `DateFix`. The `ON` clause tells SQLite how to link these two tables together. It says that if there is a row in `crime_old` with a particular `ID`, then it can find its associated row in the `DateFix` table by finding the matching value in the `DateFix`'s `ID` column. For every column in the `SELECT` clause, we have included the table from where SQLite should find the column. Technically, we only need to prefix the column with the table name when there might be confusion. For example, both `crime_old` and `DateFix` have a column called `ID`. However, we like to be explicit in complicated queries to remind ourselves from where all the data comes. 

You can also see in this `SELECT` query why periods in column names cause problems. SQL uses the period to separate the table name from the column name. If we were to include `Case.Number` in a `SELECT` statement, then SQL would think we had a table called `Case` with a column called `Number`. Are you not glad we fixed this way back when we first created our database? When we were cleaning up the Chicago crime CSV file we ran this code on the first line in the CSV file.
```{r}
#| eval: false
readLines(infile, n=1) |>
   gsub(",", ";", x=_) |> # separate with ;
   gsub(" ", "", x=_)  |> # SQL doesn't like field names with .,-,space
   writeLines(con=outfile)
```
R typically renames column names with spaces by replacing the spaces with periods. Right at the beginning we deleted any spaces in column names so that we get `CaseNumber` instead of `Case Number` or `Case.Number`.

Technically, `Beat`, `District`, `Ward`, and `CommunityArea` are all redundant information once we have `Latitude` and `Longitude`. However, "spatial joins," linking coordinates to spatial areas, is computationally expensive so that it is more efficient to simply leave this redundant information here. Lastly, note that the first line is a `CREATE TABLE` statement that will store the results of this query in a new table called `crime`.

Let's look at the newly cleaned up table.
```{r}
dbGetQuery(con, "
  SELECT *
  FROM crime
  LIMIT 10")
```
Note that the dates are formatted properly and both `PrimaryType` and `FBICode` have been eliminated from the table. If everything looks as expected, then we can delete the `crime_old` and the `DateFix` tables.
```{r}
dbExecute(con, "DROP TABLE crime_old")
dbExecute(con, "DROP TABLE DateFix")

dbListTables(con)
```

After all this work, the size of the `chicagocrime.db` database file can become quite large. Our database file is now `r round(file.info("chicagocrime.db")$size/1000^3,1)` Gb, much larger than the size of the file we downloaded from the City of Chicago open data site. Even though we have deleted the `crime_old` and `DateFix` tables, SQLite simply marks them as deleted, but does not necessarily give up the space that it had allocated for their storage. It holds onto that space in case the user needs it. The `VACUUM` statement will clean up unused space, but it can take a minute.
```{r vacuum}
dbExecute(con, "VACUUM")
```

After `VACUUM`, our `chicagocrime.db` file is now `r round(file.info("chicagocrime.db")$size/1000^3,1)` Gb... much better.

# Joining data across tables

Now that data are split across tables, we need to link tables together to get information. Let's extract the first 10 crime incidents with their case numbers and FBI codes. Since `FBICode` is no longer in the `crime` table, we need to add the table `iucr` to the `FROM` clause and link the two tables with a `JOIN`.
```{r}
timeIUCRjoin <- 
system.time(
{
   data <- dbGetQuery(con, "
       SELECT crime.CaseNumber,
              iucr.FBICode
       FROM   crime
         INNER JOIN iucr
           ON crime.iucr=iucr.iucr")
})
data |> head()
timeIUCRjoin
```
For each record in `crime`, SQLite looks up the crime's IUCR code in the `iucr` table and links in the FBI code. SQLite is fast. This query took `r timeIUCRjoin["elapsed"]` seconds, but this linking does take time, especially for really large datasets and large lookup tables. For the above query, SQLite scans through the `iucr` table until it finds the right IUCR code. This is not very efficient. If you were to look up the word "query" in the dictionary, you would not start on page 1 and scan through every word until you arrived at "query". Instead, you would start about two-thirds of the way through the dictionary, see if the words are before or after "query," and revise your search until you find the word. Rather than search hundreds of pages, you might only need to look at nine pages.

In the same way, we can create an index for the `iucr` table to help speed up the search. An index does not always make queries faster and can require storing a large index in some cases. Let's try this example.

```{r}
dbExecute(con, "
   CREATE INDEX iucr_idx on iucr(iucr)")
```

Let's rerun the query now and see if it made a difference.
```{r}
timeIUCRjoinIndex <- 
system.time(
{
   data <- dbGetQuery(con, "
       SELECT crime.CaseNumber,
              iucr.FBICode
       FROM   crime
         INNER JOIN iucr
           ON crime.iucr=iucr.iucr")
})
timeIUCRjoinIndex
```
That query now takes `r timeIUCRjoinIndex["elapsed"]` seconds. Creating an index is not always worth it. If you have queries that are taking too long, it is worth experimenting with creating an index to see if it helps.

You may come across SQL queries that join two tables with a `WHERE` clause like this.
```{r}
data <- dbGetQuery(con, "
    SELECT crime.CaseNumber,
           iucr.FBICode
    FROM crime, iucr
    WHERE crime.iucr=iucr.iucr")
```
Technically this is a legal SQL join query. However, most SQL programmers prefer using `JOIN` rather than using the `WHERE` clause. The primary reason is readability. The thinking is that the `WHERE` clause should really be about filtering which cases to include, while joining tables is quite a different operation. 

There are also several different kinds of joins. What should the query return if a crime has an IUCR code that does not appear in the `iucr` table? `JOIN`s more carefully define the desired behavior. An `INNER JOIN` returns only the rows where the join keys (the columns we use to link tables like `crime.iucr`) exist in both tables. All other rows are dropped. SQL interprets joins using the WHERE clause implicitly as an `INNER JOIN`.

Generally, in social science, we do not want to drop a row simply because its IUCR code does not appear in the lookup table. We would probably rather code its `PrimaryType` and `FBICode` as missing rather than drop the row. A `LEFT JOIN` forces every record in `crime` (the "left" table) to appear in the final result set even if it cannot find an IUCR code in `iucr`. It will simply report `NA` for its `FBICode`. More precisely, `LEFT JOIN` is synonymous with a `LEFT OUTER JOIN` (the `OUTER` keyword is optional).

For a helpful, visual description of the different kinds of joins, visit [this site](http://blog.codinghorror.com/a-visual-explanation-of-sql-joins/).

Let's determine how many assaults occurred in each ward. Since the crime type is stored in `iucr.PrimaryType`, we need to join the tables.
```{r}
dbGetQuery(con, "
    SELECT COUNT(*) AS crimecount,
           crime.Ward
    -- Use LEFT JOIN to link the two tables 
    FROM crime
       LEFT JOIN iucr
          ON crime.iucr=iucr.iucr
    -- Use WHERE to filter cases we want
    WHERE iucr.PrimaryType='ASSAULT'
    GROUP BY crime.Ward")
```

Let's tabulate how many Part 1 crimes occur in each year. We will use `PrimaryType` to give useful labels, `STRFTIME()` to extract the year in which each crime occurred, `FBICode` to pick out the Part 1 crimes, and a `LEFT JOIN` to link the tables.

```{r}
dbGetQuery(con, "
   SELECT iucr.PrimaryType           AS type,
          STRFTIME('%Y', crime.date) AS year,
          COUNT(*)                   AS crimecount
   FROM crime
     INNER JOIN iucr
       ON crime.iucr=iucr.iucr
   WHERE iucr.FBICode IN ('01A','02','03','04A','04B','05','06','07','09')
   GROUP BY type, year")
```

## Exercises

`r .exNum('Count the number of arrests for "MOTOR VEHICLE THEFT"')`

`r .exNum('Which District has the most thefts?')`. You can first try doing this with a mix of SQL and R. Once you do that, try finding another solution that only uses SQL (and two CTEs in a `WITH` clause separated by a comma).


# Subqueries

Sometimes we would like to use the results of one query as part of another query. You can put `SELECT` statements inside `FROM` statements to accomplish this. We will use this method to see if addresses are always geocoded to the same coordinates. Here are the unique combinations of addresses and coordinates. We will just show the first 20.
```{r}
dbGetQuery(con, "
   SELECT DISTINCT Block, Longitude, Latitude
   FROM crime
   LIMIT 20")
```
The crime table has at least one row with each of these combinations of `Block`, `Longitude`, and `Latitude`.

We would like to know if `Block` shows up multiple times in these results or just once. We use the results of this query in the `FROM` clause and count up the frequency of each `Block`.
```{r SQLDistinctBlocks}
dbGetQuery(con, "
   SELECT COUNT(*) AS Blockcount, 
          Block
   FROM
     (SELECT DISTINCT block,
                      Longitude,
                      Latitude
      FROM crime)
   GROUP BY block
   ORDER BY blockcount DESC
   LIMIT 20")
```
Clearly, the coordinates are not unique to each address. The addresses are "rounded" to provide some privacy, but the coordinates appear to be scattered. Why? The Chicago data portal notes "This location is shifted from the actual location for partial redaction but falls on the same block."

Rather than place subqueries in the `FROM` clause, the more modern preference is to use Common Table Expressions like we did earlier. Rewritten as a CTE:
```{r SQLDistinctBlocksCTE}
dbGetQuery(con, "
 WITH
    XYBlockUnique AS
      (SELECT DISTINCT block,
              Longitude,
              Latitude
       FROM crime)
 SELECT COUNT(*) AS blockcount,
        block
 FROM XYBlockUnique
 GROUP BY block
 ORDER BY blockcount DESC
 LIMIT 20")
```
If you are going to use the CTE or subquery in multiple queries, then it is better to `CREATE TEMPORARY TABLE`, which we will encounter later.

After completing the final exercise, remember to run `dbDisconnect(con)` to disconnect from the database. 

## Exercise
As a final exercise that does not involve a subquery:

`r .exNum('Count the number of assaults, since 2016, that occurred on Fridays and Saturdays, after 6pm, reporting the date, day of week, hour of the day, and year')`


# Solutions


`r .exQ(1)`

```{r}
dbGetQuery(con, "
  SELECT * from iucr
  LIMIT 20")
```

`r .exQ(2)`

```{r}
dbGetQuery(con, "
   SELECT iucr
   FROM iucr
   WHERE PrimaryType='KIDNAPPING'")
```

`r .exQ(3)`

```{r}
dbGetQuery(con, "
   SELECT *
   FROM iucr
   WHERE PrimaryType='ASSAULT'")
```

`r .exQ(4)`

```{r}
dbGetQuery(con, "
   SELECT COUNT(*)
   FROM iucr
   WHERE PrimaryType='ASSAULT'")
```

`r .exQ(5)`

```{r}
dbGetQuery(con, "
   SELECT COUNT(*) as MVTArrestCount
   FROM crime
      INNER JOIN iucr ON
         crime.iucr=iucr.iucr
   WHERE crime.Arrest='true' AND
         iucr.PrimaryType='MOTOR VEHICLE THEFT'")
```

`r .exQ(6)`

```{r Solution6}
a <- dbGetQuery(con, "
   SELECT COUNT(*) AS crimecount,
          District
   FROM crime
      INNER JOIN iucr ON
         crime.iucr=iucr.iucr
   WHERE iucr.PrimaryType='THEFT'
   GROUP BY District")

a |>
   filter(crimecount==max(crimecount))
# or
a |>
   slice_max(crimecount, with_ties=TRUE)

# or with a CTE
dbGetQuery(con, "
WITH 
   -- first CTE counts thefts by district
   DistrictCountCTE AS 
      (SELECT COUNT(*) AS crimecount,
              District
       FROM crime
          INNER JOIN iucr ON
             crime.iucr=iucr.iucr
       WHERE iucr.PrimaryType='THEFT'
       GROUP BY District),
   -- second CTE finds the max theft count
   MaxCountCTE AS
      (SELECT MAX(crimecount) AS MaxCrimeCount
       FROM DistrictCountCTE)
-- main query selects the district(s) matching the max       
SELECT District, crimecount
FROM DistrictCountCTE
   INNER JOIN MaxCountCTE
      ON DistrictCountCTE.crimecount = MaxCountCTE.MaxCrimeCount
")

```

`r .exQ(7)`

```{r}
#  count 1) assaults
#        2) since 2016 on
#        3) Fridays and Saturdays
#        4) after 6pm
# report 5) count,
#        6) date,
#        7) day of week, and
#        8) hour of the day
#        9) year
dbGetQuery(con, "
   SELECT COUNT(*),
          DATE(crime.date) AS crimdate,
          CAST(STRFTIME('%w',crime.date) AS INTEGER) AS weekday,
          CAST(STRFTIME('%H',crime.date) AS INTEGER) AS hour,
          CAST(STRFTIME('%Y',crime.date) AS INTEGER) AS year
   FROM   crime
             INNER JOIN iucr ON
                crime.iucr=iucr.iucr
   WHERE  iucr.PrimaryType='ASSAULT' AND
          year>=2016 AND
          weekday>=5 AND
          hour>=18
   GROUP BY crimdate, weekday, hour, year
   LIMIT 20")
```


```{r}
dbDisconnect(con)
```
